# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nX9-16KIGhhCDQ6sRSxKoRWb2SqhOUq3
"""

from sklearn.feature_extraction.text import CountVectorizer  # lib for ML
from sklearn.metrics import accuracy_score
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
import math

# read the reviews and their polarities from a given file


def loadData(fname):
    reviews = []
    labels = []
    f = open(fname)  # open file
    for line in f:
        review, rating = line.strip().split('\t')
        reviews.append(review.lower())  # reviews
        # label=rating; using 0&1 for the label hence int is used
        labels.append(int(rating))
    f.close()
    return reviews, labels


# 1 doc in every line of the text file
rev_train, labels_train = loadData('reviews_train.txt')
rev_test, labels_test = loadData('reviews_test.txt')


# Build a counter based on the training dataset
# count number of times the unique word occurs, word-its freq
counter = CountVectorizer()
counter.fit(rev_train)  # just take train words


# count the number of times each term appears in a document and transform each doc into a count vector
counts_train = counter.transform(rev_train)  # transform the training data
counts_test = counter.transform(rev_test)  # transform the testing data


clf = MLPClassifier(hidden_layer_sizes=(
    15,), random_state=1, max_iter=13, warm_start=True)

# clf = RandomForestClassifier(n_estimators=2500, n_jobs=15,criterion="entropy",max_features='log2',random_state=150,max_depth=600,min_samples_split=163)

# train all classifier on the same datasets
clf.fit(counts_train, labels_train)  # build model, doc,its lable

# use hard voting to predict (majority voting)
pred = clf.predict(counts_test)

# print(pred,labels_test)
print("Accuracy score : ",accuracy_score(pred, labels_test),"\n")

# print(pred,labels_test)
print("Error rate : ",1 - accuracy_score(pred, labels_test),"\n")

#print accuracy
print ("PREDICTION  ACTUAL_TEST_LABEL")
for e,f in zip(pred,labels_test):
  print ("   ",e,"  -->  ",f)